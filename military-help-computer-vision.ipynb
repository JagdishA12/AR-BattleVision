{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c5019",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:16:23.236361Z",
     "iopub.status.busy": "2024-11-26T13:16:23.236021Z",
     "iopub.status.idle": "2024-11-26T13:17:17.002503Z",
     "shell.execute_reply": "2024-11-26T13:17:17.001818Z"
    },
    "papermill": {
     "duration": 53.772244,
     "end_time": "2024-11-26T13:17:17.004575",
     "exception": false,
     "start_time": "2024-11-26T13:16:23.232331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSD MobileNet model loaded.\n",
      "MoveNet model loaded.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "from tensorflow.keras.metrics import Precision, Recall, F1Score\n",
    "\n",
    "# Directory to save models\n",
    "model_dir = \"pretrained_models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Load SSD MobileNet model\n",
    "ssd_model_path = os.path.join(model_dir, \"ssd_mobilenet_v2\")\n",
    "if not os.path.exists(ssd_model_path):\n",
    "    object_detection = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
    "    tf.saved_model.save(object_detection, ssd_model_path)\n",
    "else:\n",
    "    object_detection = hub.load(ssd_model_path)\n",
    "print(\"SSD MobileNet model loaded.\")\n",
    "\n",
    "# Load MoveNet model\n",
    "movenet_model_path = os.path.join(model_dir, \"movenet_thunder\")\n",
    "if not os.path.exists(movenet_model_path):\n",
    "    posture_detection = hub.load(\"https://tfhub.dev/google/movenet/singlepose/thunder/4\")\n",
    "    tf.saved_model.save(posture_detection, movenet_model_path)\n",
    "else:\n",
    "    posture_detection = hub.load(movenet_model_path)\n",
    "print(\"MoveNet model loaded.\")\n",
    "\n",
    "# Friendly QR data\n",
    "FRIENDLY_QR_CODES = {\"friend1\", \"friend2\", \"team123\"}\n",
    "\n",
    "# Camouflage detection model\n",
    "camouflage_model = tf.keras.models.load_model(\n",
    "    '\"pretrained_models/Camoflauge/camoflague_detection.keras\"',\n",
    "    custom_objects={'f1_score': F1Score(), 'Precision': Precision(), 'Recall': Recall()}\n",
    ")\n",
    "\n",
    "# Hostility scoring parameters\n",
    "WEAPON_WEIGHT = 0.5\n",
    "POSTURE_WEIGHT = 0.3\n",
    "GEAR_WEIGHT = 0.2\n",
    "CAMOUFLAGE_WEIGHT = 0.3\n",
    "HOSTILITY_THRESHOLD = 0.7\n",
    "\n",
    "# Detection functions\n",
    "def detect_objects(image, model):\n",
    "    image_uint8 = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "    input_tensor = image_uint8[tf.newaxis, ...]\n",
    "    detections = model(input_tensor)\n",
    "    return detections\n",
    "\n",
    "def detect_posture(image, model):\n",
    "    infer = model.signatures['serving_default']\n",
    "    input_image = tf.image.resize(image, [256, 256])\n",
    "    input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "    input_image = input_image[tf.newaxis, ...]\n",
    "    outputs = infer(input_image)\n",
    "    keypoints = outputs['output_0'][0][0]\n",
    "    return keypoints\n",
    "\n",
    "def detect_camouflage(image):\n",
    "    image_resized = cv2.resize(image, (128, 128))\n",
    "    image_normalized = image_resized / 255.0\n",
    "    mask = camouflage_model.predict(np.expand_dims(image_normalized, axis=0))\n",
    "    return mask[0, :, :, 0]\n",
    "\n",
    "def apply_camouflage_mask(frame, mask):\n",
    "    mask_resized = cv2.resize(mask, (frame.shape[1], frame.shape[0]))\n",
    "    mask_binary = (mask_resized > 0.5).astype(np.uint8)\n",
    "    mask_colored = np.zeros_like(frame)\n",
    "    mask_colored[:, :, 2] = mask_binary * 255  # Apply red color to the mask\n",
    "    return cv2.addWeighted(frame, 1, mask_colored, 0.5, 0)\n",
    "\n",
    "def classify_friend_or_foe(frame):\n",
    "    qr_detector = cv2.QRCodeDetector()\n",
    "    data, bbox, _ = qr_detector.detectAndDecode(frame)\n",
    "    if data:\n",
    "        return 'Friend' if data in FRIENDLY_QR_CODES else 'FOE', bbox\n",
    "    return None, None\n",
    "\n",
    "def calculate_hostility_score(detections, keypoints, camouflage_mask):\n",
    "    hostility_score = 0\n",
    "    weapon_detected = False\n",
    "    for detection in detections['detection_classes'][0].numpy():\n",
    "        if detection == 1:  # Weapon class in COCO\n",
    "            weapon_detected = True\n",
    "            hostility_score += WEAPON_WEIGHT\n",
    "            break\n",
    "\n",
    "    if keypoints is not None:\n",
    "        left_wrist, right_wrist, nose = keypoints[9], keypoints[10], keypoints[0]\n",
    "        if left_wrist[1] < nose[1] and right_wrist[1] < nose[1]:\n",
    "            hostility_score += POSTURE_WEIGHT\n",
    "\n",
    "    if camouflage_mask is not None and np.any(camouflage_mask > 0.5):\n",
    "        hostility_score += CAMOUFLAGE_WEIGHT\n",
    "\n",
    "    return hostility_score, weapon_detected\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d7ea6e",
   "metadata": {},
   "source": [
    "Enter Video Path Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video = 'Examples/New Project - Made with Clipchamp.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f8015",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:17:17.009278Z",
     "iopub.status.busy": "2024-11-26T13:17:17.008993Z",
     "iopub.status.idle": "2024-11-26T13:17:39.846359Z",
     "shell.execute_reply": "2024-11-26T13:17:39.845330Z"
    },
    "papermill": {
     "duration": 22.841995,
     "end_time": "2024-11-26T13:17:39.848477",
     "exception": false,
     "start_time": "2024-11-26T13:17:17.006482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732627044.085457      64 service.cc:145] XLA service 0x7b8d08003060 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732627044.085511      64 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732627045.240200      64 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Video processing\n",
    "\n",
    "cap = cv2.VideoCapture(input_video)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_video_path = 'processed_video.mp4'\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width, frame_height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    detections = detect_objects(rgb_frame, object_detection)\n",
    "    keypoints = detect_posture(rgb_frame, posture_detection)\n",
    "    camouflage_mask = detect_camouflage(frame)\n",
    "\n",
    "    # Highlight camouflage in the frame\n",
    "    frame = apply_camouflage_mask(frame, camouflage_mask)\n",
    "\n",
    "    # Friend or Foe classification\n",
    "    classification, bbox = classify_friend_or_foe(frame)\n",
    "    hostility_score, weapon_detected = calculate_hostility_score(detections, keypoints, camouflage_mask)\n",
    "\n",
    "    for i in range(int(detections['num_detections'][0].numpy())):\n",
    "        detection_score = detections['detection_scores'][0][i].numpy()\n",
    "        if detection_score > 0.5:\n",
    "            class_id = int(detections['detection_classes'][0][i].numpy())\n",
    "            ymin, xmin, ymax, xmax = detections['detection_boxes'][0][i].numpy()\n",
    "            left, top, right, bottom = int(xmin * frame.shape[1]), int(ymin * frame.shape[0]), int(xmax * frame.shape[1]), int(ymax * frame.shape[0])\n",
    "            color = (255, 0, 0) if classification == \"Friend\" else (0, 255, 0) if hostility_score < HOSTILITY_THRESHOLD else (0, 0, 255)\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 3)\n",
    "            label = f\"{classification} (Score: {hostility_score:.2f})\" if classification else f\"Hostility {hostility_score:.2f}\"\n",
    "            cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print('Output video saved at:', output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe53d4c",
   "metadata": {
    "papermill": {
     "duration": 0.006892,
     "end_time": "2024-11-26T13:17:39.862992",
     "exception": false,
     "start_time": "2024-11-26T13:17:39.856100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6068633,
     "sourceId": 9999943,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 82.654262,
   "end_time": "2024-11-26T13:17:43.498238",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-26T13:16:20.843976",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
